{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bdafc633",
      "metadata": {
        "id": "bdafc633"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhodes-byu/stat-486/blob/main/notebooks/05-classification-and-regression-metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b></b></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3730d7",
      "metadata": {
        "id": "ff3730d7"
      },
      "source": [
        "# Binary Classification and Regression Metrics\n",
        "## A Comprehensive Student-Guided Overview\n",
        "\n",
        "In this notebook, you will learn to calculate classification and regression metrics from first principles. Rather than relying solely on scikit-learn's built-in functions, you'll implement these metrics manually to understand exactly what they measure and how they work.\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Understand the components of a confusion matrix\n",
        "- Build binary classification metrics from scratch\n",
        "- Learn when to use different metrics\n",
        "- Implement regression evaluation metrics\n",
        "- Verify your implementations against scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac3d469b",
      "metadata": {
        "id": "ac3d469b"
      },
      "source": [
        "## Part 1: Binary Classification Metrics\n",
        "\n",
        "### 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b71a737b",
      "metadata": {
        "id": "b71a737b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, classification_report,\n",
        "    mean_squared_error, mean_absolute_error, r2_score\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "274d0ede",
      "metadata": {
        "id": "274d0ede"
      },
      "source": [
        "### 2. Create Sample Binary Classification Data\n",
        "\n",
        "For this exercise, we'll use a medical diagnosis scenario: predicting whether a patient has a disease (1) or does not have it (0) based on diagnostic test results. This is a realistic, non-trivial example where metrics matter greatly.\n",
        "\n",
        "**Scenario:** A hospital has developed a diagnostic test. We have the true disease status and the predicted status from the test for 100 patients. The hospital wants to understand how well the test performs across different metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d644a0e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d644a0e4",
        "outputId": "8612785b-e3a6-43a0-d2a9-c3f8d453c05d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of first 10 predictions:\n",
            "   True Label  Predicted Label  Match\n",
            "0           1                1   True\n",
            "1           1                1   True\n",
            "2           1                0  False\n",
            "3           0                0   True\n",
            "4           0                0   True\n",
            "5           1                1   True\n",
            "6           1                1   True\n",
            "7           0                0   True\n",
            "8           0                1  False\n",
            "9           1                1   True\n",
            "\n",
            "Total samples: 100\n",
            "Patients with disease in true labels: 53\n",
            "Patients without disease in true labels: 47\n"
          ]
        }
      ],
      "source": [
        "# Create realistic diagnostic test data\n",
        "# True disease status: 1 = has disease, 0 = does not have disease\n",
        "true_labels = np.array([\n",
        "    1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
        "    0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
        "    1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
        "    1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
        "    0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
        "    1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
        "    0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
        "    1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
        "    0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
        "    1, 1, 0, 1, 0, 0, 1, 1, 1, 0\n",
        "])\n",
        "\n",
        "# Predicted labels from the diagnostic test\n",
        "predicted_labels = np.array([\n",
        "    1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
        "    0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
        "    1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
        "    1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
        "    0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
        "    1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
        "    0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
        "    1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
        "    0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
        "    1, 1, 0, 1, 0, 1, 1, 1, 1, 0\n",
        "])\n",
        "\n",
        "# Create a dataframe to visualize some examples\n",
        "data_sample = pd.DataFrame({\n",
        "    'True Label': true_labels[:10],\n",
        "    'Predicted Label': predicted_labels[:10],\n",
        "    'Match': true_labels[:10] == predicted_labels[:10]\n",
        "})\n",
        "\n",
        "print(\"Sample of first 10 predictions:\")\n",
        "print(data_sample)\n",
        "print(f\"\\nTotal samples: {len(true_labels)}\")\n",
        "print(f\"Patients with disease in true labels: {np.sum(true_labels)}\")\n",
        "print(f\"Patients without disease in true labels: {len(true_labels) - np.sum(true_labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03745bd7",
      "metadata": {
        "id": "03745bd7"
      },
      "source": [
        "### 3. Build a Confusion Matrix\n",
        "\n",
        "A **confusion matrix** is the foundation for all binary classification metrics. It breaks down predictions into four categories:\n",
        "\n",
        "| | Predicted Negative | Predicted Positive |\n",
        "|---|---|---|\n",
        "| **Actually Negative** | True Negative (TN) | False Positive (FP) |\n",
        "| **Actually Positive** | False Negative (FN) | True Positive (TP) |\n",
        "\n",
        "**Task:** Create a confusion matrix manually using NumPy. A confusion matrix is simply a 2Ã—2 array that counts:\n",
        "- **TN**: Correct negative predictions (predicted 0, actually 0)\n",
        "- **FP**: Incorrect positive predictions (predicted 1, actually 0) - Type I Error\n",
        "- **FN**: Incorrect negative predictions (predicted 0, actually 1) - Type II Error\n",
        "- **TP**: Correct positive predictions (predicted 1, actually 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5b3452cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b3452cf",
        "outputId": "fab30500-1a9b-4f3f-f867-700386890db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (manually built):\n",
            "       Pred=0  Pred=1\n",
            "True=0   40      7\n",
            "True=1    5     48\n",
            "\n",
            "True Negatives (TN):  40\n",
            "False Positives (FP): 7\n",
            "False Negatives (FN): 5\n",
            "True Positives (TP):  48\n",
            "\n",
            "Total samples: 100\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build the confusion matrix manually\n",
        "# Create a function that takes true_labels and predicted_labels and returns the confusion matrix components\n",
        "# Following sklearn conventions, inputs should be the labels, and outputs should be the components\n",
        "#\n",
        "# Hint: Use boolean comparisons on true_labels and predicted_labels\n",
        "# TN: where both are 0\n",
        "# FP: where predicted is 1 but true is 0\n",
        "# FN: where predicted is 0 but true is 1\n",
        "# TP: where both are 1\n",
        "\n",
        "def confusion_matrix_components(true_labels, predicted_labels):\n",
        "    TN = np.sum((true_labels == 0) & (predicted_labels == 0))\n",
        "    FP = np.sum((true_labels == 0) & (predicted_labels == 1))\n",
        "    FN = np.sum((true_labels == 1) & (predicted_labels == 0))\n",
        "    TP = np.sum((true_labels == 1) & (predicted_labels == 1))\n",
        "    pass\n",
        "\n",
        "    return TN, FP, FN, TP\n",
        "\n",
        "# Call the function with our data\n",
        "TN, FP, FN, TP = confusion_matrix_components(true_labels, predicted_labels)\n",
        "\n",
        "# Create confusion matrix as a 2x2 array\n",
        "# Convention: rows = actual, columns = predicted\n",
        "confusion_matrix_manual = np.array([\n",
        "    [TN, FP],  # Row 0: Actually Negative\n",
        "    [FN, TP]   # Row 1: Actually Positive\n",
        "])\n",
        "\n",
        "print(\"Confusion Matrix (manually built):\")\n",
        "print(f\"       Pred=0  Pred=1\")\n",
        "print(f\"True=0  {TN:3d}    {FP:3d}\")\n",
        "print(f\"True=1  {FN:3d}    {TP:3d}\")\n",
        "print()\n",
        "print(f\"True Negatives (TN):  {TN}\")\n",
        "print(f\"False Positives (FP): {FP}\")\n",
        "print(f\"False Negatives (FN): {FN}\")\n",
        "print(f\"True Positives (TP):  {TP}\")\n",
        "print(f\"\\nTotal samples: {TN + FP + FN + TP}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca1c87f",
      "metadata": {
        "id": "fca1c87f"
      },
      "source": [
        "### 4. Calculate True Positives, False Positives, True Negatives, False Negatives\n",
        "\n",
        "You've already extracted these values above! Let's visualize the confusion matrix to better understand the distribution of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "611f6ed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "611f6ed7",
        "outputId": "ea2729dc-038f-404d-81a6-f0e7f8392eb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix Breakdown:\n",
            "- Correctly predicted as healthy (TN): 40\n",
            "- Incorrectly flagged as sick (FP):    7\n",
            "- Missed disease cases (FN):           5\n",
            "- Correctly predicted as sick (TP):    48\n"
          ]
        }
      ],
      "source": [
        "# Visualize the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix_manual, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "            yticklabels=['Actually Negative', 'Actually Positive'],\n",
        "            cbar_kws={'label': 'Count'}, ax=ax)\n",
        "ax.set_title('Confusion Matrix: Disease Diagnosis Test', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('True Label', fontsize=12)\n",
        "ax.set_xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"Confusion Matrix Breakdown:\")\n",
        "print(f\"- Correctly predicted as healthy (TN): {TN}\")\n",
        "print(f\"- Incorrectly flagged as sick (FP):    {FP}\")\n",
        "print(f\"- Missed disease cases (FN):           {FN}\")\n",
        "print(f\"- Correctly predicted as sick (TP):    {TP}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6c2ea1",
      "metadata": {
        "id": "cb6c2ea1"
      },
      "source": [
        "### 5. Implement Accuracy from Scratch\n",
        "\n",
        "**Accuracy** measures the proportion of correct predictions out of all predictions:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
        "\n",
        "**When to use:** Use accuracy when classes are balanced and all errors have equal cost. WARNING: Accuracy can be misleading with imbalanced datasets.\n",
        "\n",
        "**Task:** Implement the accuracy formula using the values you calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "491ea548",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "491ea548",
        "outputId": "f8be0807-aa2b-45c4-8322-d8174f1bcf0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (manual): 0.8800\n",
            "Accuracy (as percentage): 88.00%\n",
            "Interpretation: The test correctly identified disease status in 88.0% of cases.\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement accuracy\n",
        "def accuracy_manual(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate accuracy from true and predicted labels.\"\"\"\n",
        "    # Your code here:\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    pass\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "accuracy = accuracy_manual(true_labels, predicted_labels)\n",
        "print(f\"Accuracy (manual): {accuracy:.4f}\")\n",
        "print(f\"Accuracy (as percentage): {accuracy * 100:.2f}%\")\n",
        "print(f\"Interpretation: The test correctly identified disease status in {accuracy * 100:.1f}% of cases.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "671a0985",
      "metadata": {
        "id": "671a0985"
      },
      "source": [
        "### 6. Implement Precision from Scratch\n",
        "\n",
        "**Precision** measures the proportion of positive predictions that were correct:\n",
        "\n",
        "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "**Meaning:** \"Of all the cases where the test said 'sick', how many were actually sick?\"\n",
        "\n",
        "**When to use:** Use precision when false positives are costly (e.g., unnecessary treatment, false alarms).\n",
        "\n",
        "**Task:** Implement the precision formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8288191e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8288191e",
        "outputId": "e1e8c838-ff99-465f-aca4-ddc9a63ae155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (manual): 0.8727\n",
            "Precision (as percentage): 87.27%\n",
            "Interpretation: Of the 55 positive predictions, 48 were correct.\n",
            "False alarm rate among positive predictions: 12.7%\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement precision\n",
        "def precision_manual(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate precision from true and predicted labels.\"\"\"\n",
        "    # Your code here:\n",
        "    precision = TP / (TP + FP)\n",
        "    pass\n",
        "\n",
        "    return precision\n",
        "\n",
        "precision = precision_manual(true_labels, predicted_labels)\n",
        "print(f\"Precision (manual): {precision:.4f}\")\n",
        "print(f\"Precision (as percentage): {precision * 100:.2f}%\")\n",
        "print(f\"Interpretation: Of the {TP + FP} positive predictions, {TP} were correct.\")\n",
        "print(f\"False alarm rate among positive predictions: {(FP / (TP + FP)) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3690e89",
      "metadata": {
        "id": "d3690e89"
      },
      "source": [
        "### 7. Implement Recall (Sensitivity) from Scratch\n",
        "\n",
        "**Recall** (also called **Sensitivity** or **True Positive Rate**) measures the proportion of actual positives that were correctly identified:\n",
        "\n",
        "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "\n",
        "**Meaning:** \"Of all the patients who actually have the disease, how many did the test catch?\"\n",
        "\n",
        "**When to use:** Use recall when false negatives are costly (e.g., missing cancer diagnosis means the disease goes untreated).\n",
        "\n",
        "**Task:** Implement the recall formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "11887b29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11887b29",
        "outputId": "da192853-b544-4511-93c4-93ea33869ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall (manual): 0.9057\n",
            "Recall (as percentage): 90.57%\n",
            "Interpretation: The test caught 90.6% of actual disease cases.\n",
            "Missed diagnosis rate: 9.4%\n",
            "\n",
            "âš ï¸ Important: High recall means fewer missed diagnoses!\n",
            "   In medicine, missing a disease is often worse than a false positive.\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement recall (sensitivity)\n",
        "def recall_manual(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate recall from true and predicted labels.\"\"\"\n",
        "    # Your code here:\n",
        "    recall = TP / (TP + FN)\n",
        "    pass\n",
        "    return recall\n",
        "recall = recall_manual(true_labels, predicted_labels)\n",
        "print(f\"Recall (manual): {recall:.4f}\")\n",
        "print(f\"Recall (as percentage): {recall * 100:.2f}%\")\n",
        "print(f\"Interpretation: The test caught {recall * 100:.1f}% of actual disease cases.\")\n",
        "print(f\"Missed diagnosis rate: {(FN / (TP + FN)) * 100:.1f}%\")\n",
        "print()\n",
        "print(\"âš ï¸ Important: High recall means fewer missed diagnoses!\")\n",
        "print(\"   In medicine, missing a disease is often worse than a false positive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25732be",
      "metadata": {
        "id": "e25732be"
      },
      "source": [
        "### 8. Implement Specificity from Scratch\n",
        "\n",
        "**Specificity** (also called **True Negative Rate**) measures the proportion of actual negatives that were correctly identified:\n",
        "\n",
        "$$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n",
        "\n",
        "**Meaning:** \"Of all the patients who don't have the disease, how many did the test correctly clear?\"\n",
        "\n",
        "**When to use:** Use specificity when false positives are costly. It's the complement of the False Positive Rate.\n",
        "\n",
        "**Precision vs. Specificity:**\n",
        "- Precision: Among predicted positives, how many were correct?\n",
        "- Specificity: Among actual negatives, how many were correctly predicted as negative?\n",
        "\n",
        "**Task:** Implement the specificity formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "924187a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "924187a9",
        "outputId": "7961773b-3602-4be2-be51-4b6846049c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specificity (manual): 0.8511\n",
            "Specificity (as percentage): 85.11%\n",
            "Interpretation: The test correctly identified 85.1% of patients without disease.\n",
            "False positive rate among healthy patients: 14.9%\n",
            "\n",
            "Comparison:\n",
            "Precision:  TP / (TP + FP) = 48 / 55 = 0.8727\n",
            "Specificity: TN / (TN + FP) = 40 / 47 = 0.8511\n",
            "Note: Both penalize False Positives, but measure different things!\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement specificity\n",
        "def specificity_manual(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate specificity from true and predicted labels.\"\"\"\n",
        "    # Your code here:\n",
        "    specificity = TN / (TN + FP)\n",
        "    pass\n",
        "    return specificity\n",
        "specificity = specificity_manual(true_labels, predicted_labels)\n",
        "print(f\"Specificity (manual): {specificity:.4f}\")\n",
        "print(f\"Specificity (as percentage): {specificity * 100:.2f}%\")\n",
        "print(f\"Interpretation: The test correctly identified {specificity * 100:.1f}% of patients without disease.\")\n",
        "print(f\"False positive rate among healthy patients: {(FP / (TN + FP)) * 100:.1f}%\")\n",
        "print()\n",
        "\n",
        "# Compare precision and specificity\n",
        "print(\"Comparison:\")\n",
        "print(f\"Precision:  TP / (TP + FP) = {TP} / {TP + FP} = {precision:.4f}\")\n",
        "print(f\"Specificity: TN / (TN + FP) = {TN} / {TN + FP} = {specificity:.4f}\")\n",
        "print(\"Note: Both penalize False Positives, but measure different things!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3fd7428",
      "metadata": {
        "id": "c3fd7428"
      },
      "source": [
        "### 9. Implement F1 Score from Scratch\n",
        "\n",
        "The **F1 Score** is the harmonic mean of precision and recall. It's useful when you want to balance both metrics:\n",
        "\n",
        "$$\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "**Meaning:** F1 ranges from 0 to 1, where 1 is perfect and 0 is worst. It heavily penalizes extreme values.\n",
        "\n",
        "**When to use:** Use F1 when you want to balance precision and recall. It's especially useful for imbalanced datasets.\n",
        "\n",
        "**Why Harmonic Mean?** The harmonic mean is more sensitive to small values than the arithmetic mean. If either precision or recall is low, the F1 score will be low.\n",
        "\n",
        "**Task:** Implement the F1 score using the precision and recall you already calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e63a43ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e63a43ed",
        "outputId": "bfd8d2cf-aac4-4c6b-f20c-db700f6b5238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (manual): 0.8889\n",
            "\n",
            "Summary of all metrics so far:\n",
            "Accuracy:   0.8800\n",
            "Precision:  0.8727\n",
            "Recall:     0.9057\n",
            "Specificity: 0.8511\n",
            "F1 Score:   0.8889\n",
            "\n",
            "What do these tell us?\n",
            "- The test is 88.0% accurate overall\n",
            "- When it says 'sick', it's correct 87.3% of the time\n",
            "- It catches 90.6% of actual disease cases\n",
            "- It correctly clears 85.1% of healthy patients\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement F1 score\n",
        "def f1_score_manual(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate F1 score from true and predicted labels.\"\"\"\n",
        "    # Your code here:\n",
        "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
        "    pass\n",
        "    return f1\n",
        "\n",
        "f1 = f1_score_manual(true_labels, predicted_labels)\n",
        "print(f\"F1 Score (manual): {f1:.4f}\")\n",
        "print()\n",
        "\n",
        "# Show comparison of metrics\n",
        "print(\"Summary of all metrics so far:\")\n",
        "print(f\"Accuracy:   {accuracy:.4f}\")\n",
        "print(f\"Precision:  {precision:.4f}\")\n",
        "print(f\"Recall:     {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1 Score:   {f1:.4f}\")\n",
        "print()\n",
        "print(\"What do these tell us?\")\n",
        "print(f\"- The test is {accuracy*100:.1f}% accurate overall\")\n",
        "print(f\"- When it says 'sick', it's correct {precision*100:.1f}% of the time\")\n",
        "print(f\"- It catches {recall*100:.1f}% of actual disease cases\")\n",
        "print(f\"- It correctly clears {specificity*100:.1f}% of healthy patients\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee139514",
      "metadata": {
        "id": "ee139514"
      },
      "source": [
        "### 10. Implement False Positive Rate from Scratch\n",
        "\n",
        "The **False Positive Rate (FPR)** is the proportion of actual negatives that were incorrectly predicted as positive:\n",
        "\n",
        "$$\\text{FPR} = \\frac{FP}{FP + TN} = 1 - \\text{Specificity}$$\n",
        "\n",
        "**Meaning:** \"Of all the healthy patients, what fraction did the test incorrectly flag as sick?\"\n",
        "\n",
        "**When to use:** FPR is useful for ROC curves and when you want to understand Type I errors.\n",
        "\n",
        "**Task:** Implement the FPR formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "718fb22c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "718fb22c",
        "outputId": "e62024b4-8ebc-457b-c430-3023c7dac3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positive Rate (manual): 0.1489\n",
            "FPR (as percentage): 14.89%\n",
            "Interpretation: 14.9% of healthy patients were incorrectly flagged as sick.\n",
            "\n",
            "Relationship to Specificity: 1 - Specificity = 0.1489\n",
            "FPR = 0.1489\n",
            "These should be equal! âœ“\n"
          ]
        }
      ],
      "source": [
        "# TODO: Implement false positive rate\n",
        "def fpr_manual(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate false positive rate from true and predicted labels.\"\"\"\n",
        "    # Your code here:\n",
        "    FPR = 1 - specificity\n",
        "    pass\n",
        "    return FPR\n",
        "\n",
        "fpr = fpr_manual(true_labels, predicted_labels)\n",
        "print(f\"False Positive Rate (manual): {fpr:.4f}\")\n",
        "print(f\"FPR (as percentage): {fpr * 100:.2f}%\")\n",
        "print(f\"Interpretation: {fpr * 100:.1f}% of healthy patients were incorrectly flagged as sick.\")\n",
        "print()\n",
        "print(f\"Relationship to Specificity: 1 - Specificity = {1 - specificity:.4f}\")\n",
        "print(f\"FPR = {fpr:.4f}\")\n",
        "print(f\"These should be equal! âœ“\" if abs(fpr - (1 - specificity)) < 0.0001 else \"Something is wrong!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f184554",
      "metadata": {
        "id": "0f184554"
      },
      "source": [
        "### 11. Implement ROC-AUC from Scratch\n",
        "\n",
        "Before implementing AUC, let's understand the **Receiver Operating Characteristic (ROC)** curve:\n",
        "\n",
        "**ROC Curve:** A plot that shows the trade-off between True Positive Rate (Recall) and False Positive Rate at different classification thresholds.\n",
        "\n",
        "- X-axis: False Positive Rate (FPR)\n",
        "- Y-axis: True Positive Rate (TPR = Recall)\n",
        "\n",
        "**AUC (Area Under the Curve):** The area under the ROC curve, ranging from 0 to 1.\n",
        "\n",
        "**Interpretation:**\n",
        "- **AUC = 1.0**: Perfect classifier\n",
        "- **AUC = 0.5**: Random classifier (diagonal line)\n",
        "- **AUC < 0.5**: Worse than random\n",
        "\n",
        "**When to use:** AUC is excellent for imbalanced datasets and when you want a single number to compare models. It measures the model's ability to rank positive examples higher than negative examples.\n",
        "\n",
        "**Task:** Calculate AUC manually using the trapezoidal rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630fe6ee",
      "metadata": {
        "id": "630fe6ee"
      },
      "outputs": [],
      "source": [
        "# For ROC-AUC, we need predicted probabilities (not just binary predictions)\n",
        "# Let's train a simple logistic regression model to get probabilities\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create simple features based on an arbitrary scoring function\n",
        "# (in reality, this would be model predictions or probability scores)\n",
        "# For demonstration, we'll use a score that correlates with disease status\n",
        "np.random.seed(42)\n",
        "scores = np.random.uniform(0, 1, len(true_labels))\n",
        "scores[true_labels == 1] += 0.3  # Slightly higher scores for disease cases\n",
        "scores = np.clip(scores, 0, 1)\n",
        "\n",
        "print(\"Predicted probability scores (first 20 samples):\")\n",
        "print(pd.DataFrame({\n",
        "    'True Label': true_labels[:20],\n",
        "    'Predicted Score': scores[:20],\n",
        "    'Rounded': np.round(scores[:20], 3)\n",
        "}).to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Calculate AUC using sklearn\n",
        "auc = roc_auc_score(true_labels, scores)\n",
        "print(f\"AUC (sklearn): {auc:.4f}\")\n",
        "print()\n",
        "\n",
        "# For visualization, calculate the ROC curve points\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr_list, tpr_list, _ = roc_curve(true_labels, scores)\n",
        "\n",
        "# Visualize the ROC curve\n",
        "fig, ax = plt.subplots(figsize=(8, 7))\n",
        "ax.plot(fpr_list, tpr_list, 'b-', linewidth=2, label=f'ROC Curve (AUC = {auc:.4f})')\n",
        "ax.plot([0, 1], [0, 1], 'r--', linewidth=1.5, label='Random Classifier (AUC = 0.5)')\n",
        "ax.fill_between(fpr_list, tpr_list, alpha=0.3)\n",
        "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate (Recall)', fontsize=12)\n",
        "ax.set_title('ROC Curve: Disease Diagnosis Test', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([-0.02, 1.02])\n",
        "ax.set_ylim([-0.02, 1.02])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation:\")\n",
        "print(f\"- AUC = {auc:.4f} means the model has a {auc*100:.1f}% chance of correctly ranking a random\")\n",
        "print(f\"  sick patient higher than a random healthy patient.\")\n",
        "if auc > 0.9:\n",
        "    print(\"- Excellent discrimination (AUC > 0.9)\")\n",
        "elif auc > 0.8:\n",
        "    print(\"- Good discrimination (AUC > 0.8)\")\n",
        "elif auc > 0.7:\n",
        "    print(\"- Fair discrimination (AUC > 0.7)\")\n",
        "elif auc > 0.6:\n",
        "    print(\"- Poor discrimination (AUC > 0.6)\")\n",
        "else:\n",
        "    print(\"- Very poor discrimination (AUC â‰¤ 0.6)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812df7b0",
      "metadata": {
        "id": "812df7b0"
      },
      "source": [
        "### Verify All Classification Metrics with Scikit-learn\n",
        "\n",
        "Now let's verify that your manual implementations of all classification metrics match scikit-learn's built-in functions. This is an important sanity check!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291f27a1",
      "metadata": {
        "id": "291f27a1"
      },
      "outputs": [],
      "source": [
        "# Verify with sklearn\n",
        "cm_sklearn = confusion_matrix(true_labels, predicted_labels)\n",
        "print(\"Confusion Matrix from sklearn:\")\n",
        "print(cm_sklearn)\n",
        "print()\n",
        "\n",
        "# Compare metrics\n",
        "acc_sklearn = accuracy_score(true_labels, predicted_labels)\n",
        "prec_sklearn = precision_score(true_labels, predicted_labels)\n",
        "rec_sklearn = recall_score(true_labels, predicted_labels)\n",
        "f1_sklearn = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Create comparison table\n",
        "auc_sklearn = roc_auc_score(true_labels, scores)\n",
        "comparison = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'Specificity', 'FPR', 'F1 Score'],\n",
        "    'Manual': [accuracy, precision, recall, specificity, fpr, f1],\n",
        "    'Scikit-learn': [acc_sklearn, prec_sklearn, rec_sklearn, specificity, fpr, f1_sklearn],\n",
        "})\n",
        "\n",
        "print(\"Comparison of Manual vs Scikit-learn Implementations:\")\n",
        "print(comparison.to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Check for differences\n",
        "comparison['Difference'] = abs(comparison['Manual'] - comparison['Scikit-learn'])\n",
        "max_diff = comparison['Difference'].max()\n",
        "print(f\"Maximum difference: {max_diff:.10f}\")\n",
        "if max_diff < 0.0001:\n",
        "    print(\"âœ“ All implementations match! (within numerical precision)\")\n",
        "else:\n",
        "    print(\"âš ï¸ There are differences. Check your implementations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f50290c8",
      "metadata": {
        "id": "f50290c8"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Regression Metrics\n",
        "\n",
        "Now we'll implement metrics for continuous prediction problems. Unlike classification (predicting categories), regression predicts continuous values.\n",
        "\n",
        "### 12. Create Sample Regression Data\n",
        "\n",
        "For regression, we'll use a realistic example: predicting house prices based on features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49447af1",
      "metadata": {
        "id": "49447af1"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic house price prediction data\n",
        "np.random.seed(42)\n",
        "n_samples = 50\n",
        "\n",
        "# Simulate a simple linear relationship with noise\n",
        "square_footage = np.random.uniform(1000, 5000, n_samples)\n",
        "actual_prices = 100 * square_footage + 50000 + np.random.normal(0, 50000, n_samples)\n",
        "\n",
        "# Model predictions (slightly imperfect)\n",
        "predicted_prices = 95 * square_footage + 55000 + np.random.normal(0, 30000, n_samples)\n",
        "\n",
        "# Create DataFrame\n",
        "regression_data = pd.DataFrame({\n",
        "    'Square Footage': square_footage,\n",
        "    'Actual Price ($)': actual_prices,\n",
        "    'Predicted Price ($)': predicted_prices,\n",
        "    'Residual ($)': actual_prices - predicted_prices\n",
        "})\n",
        "\n",
        "print(\"House Price Prediction Data (first 10 samples):\")\n",
        "print(regression_data.head(10).to_string(index=False))\n",
        "print(f\"\\nTotal samples: {len(regression_data)}\")\n",
        "print(f\"Price range: ${actual_prices.min():,.0f} - ${actual_prices.max():,.0f}\")\n",
        "print(f\"Mean actual price: ${actual_prices.mean():,.0f}\")\n",
        "print(f\"Mean predicted price: ${predicted_prices.mean():,.0f}\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Scatter plot\n",
        "axes[0].scatter(actual_prices, predicted_prices, alpha=0.6)\n",
        "axes[0].plot([actual_prices.min(), actual_prices.max()],\n",
        "             [actual_prices.min(), actual_prices.max()], 'r--', label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual Price ($)', fontsize=11)\n",
        "axes[0].set_ylabel('Predicted Price ($)', fontsize=11)\n",
        "axes[0].set_title('Actual vs Predicted House Prices', fontsize=12, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Residuals plot\n",
        "axes[1].scatter(actual_prices, regression_data['Residual ($)'], alpha=0.6)\n",
        "axes[1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1].set_xlabel('Actual Price ($)', fontsize=11)\n",
        "axes[1].set_ylabel('Residual (Actual - Predicted) ($)', fontsize=11)\n",
        "axes[1].set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c8666c",
      "metadata": {
        "id": "69c8666c"
      },
      "source": [
        "### 13. Implement Mean Squared Error (MSE) from Scratch\n",
        "\n",
        "**Mean Squared Error** measures the average of squared differences between predicted and actual values:\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Where:\n",
        "- $y_i$ = actual value\n",
        "- $\\hat{y}_i$ = predicted value\n",
        "- $n$ = number of samples\n",
        "\n",
        "**Characteristics:**\n",
        "- Penalizes large errors more heavily (due to squaring)\n",
        "- Always non-negative\n",
        "- Same units as the target variable squared\n",
        "\n",
        "**When to use:** MSE is commonly used in regression problems. Use it when you want to penalize outliers and large errors more.\n",
        "\n",
        "**Task:** Implement MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d91a9d",
      "metadata": {
        "id": "c2d91a9d"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement MSE\n",
        "def mse_manual(y_true, y_pred):\n",
        "    \"\"\"Calculate Mean Squared Error from true and predicted values.\"\"\"\n",
        "    # Your code here:\n",
        "    pass\n",
        "\n",
        "y_true = regression_data['Actual Price ($)'].values\n",
        "y_pred = regression_data['Predicted Price ($)'].values\n",
        "\n",
        "mse = mse_manual(y_true, y_pred)\n",
        "print(f\"Mean Squared Error (manual): ${mse:,.2f}\")\n",
        "print(f\"This is in units of $ squared: ${mse:,.2f}\")\n",
        "print()\n",
        "\n",
        "# Compare with sklearn\n",
        "mse_sklearn = mean_squared_error(y_true, y_pred)\n",
        "print(f\"Mean Squared Error (sklearn): ${mse_sklearn:,.2f}\")\n",
        "print(f\"Match: {np.isclose(mse, mse_sklearn)}\")\n",
        "print()\n",
        "\n",
        "# Interpretation\n",
        "print(f\"Average squared error: ${mse:,.2f}\")\n",
        "print(f\"This means, on average, predictions are off by âˆš{mse:,.0f} â‰ˆ ${np.sqrt(mse):,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f792410c",
      "metadata": {
        "id": "f792410c"
      },
      "source": [
        "### 14. Implement Root Mean Squared Error (RMSE) from Scratch\n",
        "\n",
        "**Root Mean Squared Error** is the square root of MSE. It's more interpretable because it's in the same units as the target variable:\n",
        "\n",
        "$$\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "**Characteristics:**\n",
        "- In the same units as the target variable (easier to interpret)\n",
        "- Still penalizes large errors heavily\n",
        "- Most commonly used metric in regression\n",
        "\n",
        "**When to use:** RMSE is often preferred over MSE because it's more interpretable.\n",
        "\n",
        "**Task:** Implement RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341c3b48",
      "metadata": {
        "id": "341c3b48"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement RMSE\n",
        "def rmse_manual(y_true, y_pred):\n",
        "    \"\"\"Calculate Root Mean Squared Error from true and predicted values.\"\"\"\n",
        "    # Your code here:\n",
        "    pass\n",
        "\n",
        "rmse = rmse_manual(y_true, y_pred)\n",
        "print(f\"Root Mean Squared Error (manual): ${rmse:,.2f}\")\n",
        "print()\n",
        "\n",
        "# Compare with sklearn (sklearn doesn't have RMSE, but we can compute it from MSE)\n",
        "rmse_sklearn = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "print(f\"Root Mean Squared Error (sklearn): ${rmse_sklearn:,.2f}\")\n",
        "print(f\"Match: {np.isclose(rmse, rmse_sklearn)}\")\n",
        "print()\n",
        "\n",
        "# Interpretation\n",
        "print(f\"âœ“ Interpretation: On average, predictions are off by ${rmse:,.2f}\")\n",
        "print(f\"  This is more interpretable than MSE because it's in dollars!\")\n",
        "print()\n",
        "print(f\"Relationship: RMSE = âˆšMSE\")\n",
        "print(f\"${rmse:,.2f} = âˆš${mse:,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9add825f",
      "metadata": {
        "id": "9add825f"
      },
      "source": [
        "### 15. Implement Mean Absolute Error (MAE) from Scratch\n",
        "\n",
        "**Mean Absolute Error** measures the average absolute difference between predicted and actual values:\n",
        "\n",
        "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
        "\n",
        "**Characteristics:**\n",
        "- Uses absolute value instead of squared error\n",
        "- Treats all errors equally (doesn't heavily penalize outliers)\n",
        "- Same units as the target variable\n",
        "- More interpretable than MSE, less sensitive to outliers than RMSE\n",
        "\n",
        "**When to use:** Use MAE when you want a metric that's robust to outliers or when all errors matter equally.\n",
        "\n",
        "**Comparison: MSE vs MAE**\n",
        "- MSE: Penalizes large errors more (quadratic)\n",
        "- MAE: Treats all errors equally (linear)\n",
        "\n",
        "**Task:** Implement MAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f2db16f",
      "metadata": {
        "id": "7f2db16f"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement MAE\n",
        "def mae_manual(y_true, y_pred):\n",
        "    \"\"\"Calculate Mean Absolute Error from true and predicted values.\"\"\"\n",
        "    # Your code here:\n",
        "    pass\n",
        "\n",
        "mae = mae_manual(y_true, y_pred)\n",
        "print(f\"Mean Absolute Error (manual): ${mae:,.2f}\")\n",
        "print()\n",
        "\n",
        "# Compare with sklearn\n",
        "mae_sklearn = mean_absolute_error(y_true, y_pred)\n",
        "print(f\"Mean Absolute Error (sklearn): ${mae_sklearn:,.2f}\")\n",
        "print(f\"Match: {np.isclose(mae, mae_sklearn)}\")\n",
        "print()\n",
        "\n",
        "# Compare MSE, RMSE, and MAE\n",
        "print(\"Comparison of Error Metrics:\")\n",
        "print(f\"MSE (penalizes large errors):  ${mse:,.2f}\")\n",
        "print(f\"RMSE (same units as target):   ${rmse:,.2f}\")\n",
        "print(f\"MAE (simple average):          ${mae:,.2f}\")\n",
        "print()\n",
        "print(\"Note: RMSE > MAE because squaring amplifies large errors.\")\n",
        "print(f\"RMSE/MAE ratio: {rmse/mae:.2f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2be17eb",
      "metadata": {
        "id": "d2be17eb"
      },
      "source": [
        "### 16. Implement Mean Absolute Percentage Error (MAPE) from Scratch\n",
        "\n",
        "**Mean Absolute Percentage Error** measures the average absolute percentage difference:\n",
        "\n",
        "$$\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100\\%$$\n",
        "\n",
        "**Characteristics:**\n",
        "- Scale-independent (expressed as percentage)\n",
        "- Easy to interpret across different datasets\n",
        "- Undefined when actual values are zero\n",
        "- All errors are weighted equally\n",
        "\n",
        "**When to use:** MAPE is useful for comparing across datasets with different scales. For example, 10% error is meaningful whether predicting prices or quantities.\n",
        "\n",
        "**Task:** Implement MAPE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420f5569",
      "metadata": {
        "id": "420f5569"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement MAPE\n",
        "def mape_manual(y_true, y_pred):\n",
        "    \"\"\"Calculate Mean Absolute Percentage Error from true and predicted values.\"\"\"\n",
        "    # Your code here:\n",
        "    pass\n",
        "\n",
        "mape = mape_manual(y_true, y_pred)\n",
        "print(f\"Mean Absolute Percentage Error (manual): {mape:.2f}%\")\n",
        "print()\n",
        "\n",
        "# Interpretation\n",
        "print(\"Interpretation:\")\n",
        "print(f\"On average, predictions deviate by {mape:.2f}% from actual values.\")\n",
        "print()\n",
        "\n",
        "# Compare with different metrics\n",
        "print(\"Summary of all regression metrics:\")\n",
        "print(f\"MSE:  ${mse:,.2f} (squared units)\")\n",
        "print(f\"RMSE: ${rmse:,.2f} (same units as target)\")\n",
        "print(f\"MAE:  ${mae:,.2f} (same units as target)\")\n",
        "print(f\"MAPE: {mape:.2f}% (percentage, scale-independent)\")\n",
        "print()\n",
        "\n",
        "# Relationship to actual prices\n",
        "mean_actual_price = y_true.mean()\n",
        "print(f\"Mean actual price: ${mean_actual_price:,.2f}\")\n",
        "print(f\"MAPE interpretation: Â±{mape:.2f}% of ${mean_actual_price:,.2f} = Â±${mean_actual_price * mape / 100:,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40cc8f41",
      "metadata": {
        "id": "40cc8f41"
      },
      "source": [
        "### 17. Implement R-squared (RÂ²) from Scratch\n",
        "\n",
        "**R-squared** measures the proportion of variance in the target variable that is explained by the model:\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}}$$\n",
        "\n",
        "Where:\n",
        "- $\\text{SS}_{\\text{res}} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ = sum of squared residuals\n",
        "- $\\text{SS}_{\\text{tot}} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$ = total sum of squares\n",
        "\n",
        "**Characteristics:**\n",
        "- Ranges from $-\\infty$ to 1 (though typically 0 to 1)\n",
        "- $R^2 = 1$: Perfect predictions\n",
        "- $R^2 = 0$: Model is as good as predicting the mean\n",
        "- $R^2 < 0$: Model is worse than predicting the mean\n",
        "\n",
        "**When to use:** RÂ² is great for understanding goodness of fit and comparing models. It's scale-independent.\n",
        "\n",
        "**Task:** Implement RÂ²."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a8f1d8",
      "metadata": {
        "id": "31a8f1d8"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement RÂ²\n",
        "def r2_score_manual(y_true, y_pred):\n",
        "    \"\"\"Calculate R-squared (coefficient of determination) from true and predicted values.\"\"\"\n",
        "    # Your code here:\n",
        "    pass\n",
        "\n",
        "r2 = r2_score_manual(y_true, y_pred)\n",
        "print(f\"RÂ² Score (manual): {r2:.4f}\")\n",
        "print()\n",
        "\n",
        "# Compare with sklearn\n",
        "r2_sklearn = r2_score(y_true, y_pred)\n",
        "print(f\"RÂ² Score (sklearn): {r2_sklearn:.4f}\")\n",
        "print(f\"Match: {np.isclose(r2, r2_sklearn)}\")\n",
        "print()\n",
        "\n",
        "# Interpretation\n",
        "print(\"Interpretation:\")\n",
        "print(f\"The model explains {r2*100:.2f}% of the variance in house prices.\")\n",
        "print(f\"This means {(1-r2)*100:.2f}% of variance is unexplained.\")\n",
        "print()\n",
        "\n",
        "# Show components\n",
        "mean_y = y_true.mean()\n",
        "ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "ss_tot = np.sum((y_true - mean_y) ** 2)\n",
        "print(f\"Components:\")\n",
        "print(f\"Sum of squared residuals (SSres): {ss_res:,.0f}\")\n",
        "print(f\"Total sum of squares (SStot):     {ss_tot:,.0f}\")\n",
        "print(f\"RÂ² = 1 - (SSres/SStot) = 1 - ({ss_res:,.0f}/{ss_tot:,.0f}) = {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2164538e",
      "metadata": {
        "id": "2164538e"
      },
      "source": [
        "### 18. Verify Regression Metrics with Scikit-learn\n",
        "\n",
        "Let's create a comprehensive summary of all regression metrics and compare with scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e743062",
      "metadata": {
        "id": "0e743062"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive comparison of regression metrics\n",
        "regression_comparison = pd.DataFrame({\n",
        "    'Metric': ['MSE', 'RMSE', 'MAE', 'MAPE (%)', 'RÂ²'],\n",
        "    'Manual': [mse, rmse, mae, mape, r2],\n",
        "    'Scikit-learn': [\n",
        "        mean_squared_error(y_true, y_pred),\n",
        "        np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "        mean_absolute_error(y_true, y_pred),\n",
        "        np.mean(np.abs((y_true - y_pred) / y_true)) * 100,  # Simple MAPE calculation\n",
        "        r2_score(y_true, y_pred)\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Calculate differences\n",
        "regression_comparison['Match'] = [\n",
        "    np.isclose(regression_comparison.loc[i, 'Manual'],\n",
        "               regression_comparison.loc[i, 'Scikit-learn'])\n",
        "    for i in range(len(regression_comparison))\n",
        "]\n",
        "\n",
        "print(\"Regression Metrics Comparison:\")\n",
        "print(\"=\"*70)\n",
        "print(regression_comparison.to_string(index=False))\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Summary interpretation\n",
        "print(\"Summary of Regression Metrics:\")\n",
        "print()\n",
        "print(f\"1. MSE = ${mse:,.2f}\")\n",
        "print(f\"   Average squared difference. Useful for optimization but hard to interpret.\")\n",
        "print()\n",
        "print(f\"2. RMSE = ${rmse:,.2f}\")\n",
        "print(f\"   Square root of MSE. In same units as target. Most commonly used.\")\n",
        "print()\n",
        "print(f\"3. MAE = ${mae:,.2f}\")\n",
        "print(f\"   Average absolute difference. Robust to outliers. Simpler than RMSE.\")\n",
        "print()\n",
        "print(f\"4. MAPE = {mape:.2f}%\")\n",
        "print(f\"   Percentage error. Scale-independent. Good for comparing across datasets.\")\n",
        "print()\n",
        "print(f\"5. RÂ² = {r2:.4f}\")\n",
        "print(f\"   Explains {r2*100:.1f}% of variance. Good for model comparison.\")\n",
        "print()\n",
        "\n",
        "# Visual comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Prediction errors distribution\n",
        "errors = y_true - y_pred\n",
        "axes[0].hist(errors, bins=15, edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
        "axes[0].set_xlabel('Prediction Error ($)', fontsize=11)\n",
        "axes[0].set_ylabel('Frequency', fontsize=11)\n",
        "axes[0].set_title('Distribution of Prediction Errors', fontsize=12, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Metrics bar chart\n",
        "metrics_values = [mse/1e7, rmse/1e3, mae/1e3, mape, r2*100]  # Scale for visibility\n",
        "metrics_names = ['MSE/10M', 'RMSE/1K', 'MAE/1K', 'MAPE', 'RÂ²Ã—100']\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "axes[1].bar(metrics_names, metrics_values, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[1].set_ylabel('Value (scaled for visibility)', fontsize=11)\n",
        "axes[1].set_title('Regression Metrics Summary', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(metrics_values):\n",
        "    axes[1].text(i, v + max(metrics_values)*0.02, f'{v:.2f}', ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902206e1",
      "metadata": {
        "id": "902206e1"
      },
      "source": [
        "## Summary and Key Takeaways\n",
        "\n",
        "### Classification Metrics\n",
        "You've learned to implement and interpret:\n",
        "- **Accuracy**: Overall correctness\n",
        "- **Precision**: Reliability of positive predictions\n",
        "- **Recall**: Coverage of actual positives\n",
        "- **Specificity**: Coverage of actual negatives\n",
        "- **F1 Score**: Harmonic mean of precision and recall\n",
        "- **False Positive Rate**: Error rate for negatives\n",
        "\n",
        "**Key Question for Classification:** What are the costs of different types of errors?\n",
        "- High false negative cost (missing disease) â†’ Prioritize Recall\n",
        "- High false positive cost (unnecessary treatment) â†’ Prioritize Precision\n",
        "- Balanced concern â†’ Use F1 Score\n",
        "\n",
        "### Regression Metrics\n",
        "You've learned to implement and interpret:\n",
        "- **MSE**: Penalizes large errors (squared)\n",
        "- **RMSE**: Square root of MSE, same units as target\n",
        "- **MAE**: Simple average error, robust to outliers\n",
        "- **MAPE**: Percentage error, scale-independent\n",
        "- **RÂ²**: Proportion of variance explained\n",
        "\n",
        "**Key Question for Regression:** How do you want to penalize errors?\n",
        "- Large errors are very bad â†’ Use MSE/RMSE\n",
        "- Errors are equally important â†’ Use MAE\n",
        "- Need scale-free comparison â†’ Use MAPE\n",
        "- Want to explain variance â†’ Use RÂ²\n",
        "\n",
        "### Important Reminders\n",
        "1. Choose metrics based on the business problem, not just convention\n",
        "2. Be aware of data imbalance and class costs\n",
        "3. Visualize predictions and errors to catch issues"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}